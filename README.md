# Awesome Masked Autoencoders

<p align="center"> <img src="mae.png" /> <p align="center"><em>Fig. 1. Masked Autoencoders from Kaiming He et al.</em></p>

Masked Autoencoder (MAE, *Kaiming He et al.*) has renewed a surge of interest due to its capacity to learn useful representations from rich unlabeled data. Until recently, MAE and its follow-up works have advanced the state-of-the-art and provided valuable insights in research (particularly vision research). Here I list several follow-up works after or concurrent with MAE to inspire future research.


# Vision
+ [ðŸ”¥Masked Autoencoders Are Scalable Vision Learners](https://arxiv.org/abs/2111.06377)
+ [ðŸ”¥SimMIM: A Simple Framework for Masked Image Modeling](https://arxiv.org/abs/2111.09886)
+ [ðŸ”¥BEIT: BERT Pre-Training of Image Transformers](https://arxiv.org/abs/2106.08254)
+ [Student Collaboration Improves Self-Supervised Learning: Dual-Loss Adaptive Masked Autoencoder for Brain Cell Image Analysis](https://arxiv.org/abs/2205.05194)
+ [A Mask-Based Adversarial Defense Scheme](https://arxiv.org/abs/2204.11837)
+ [Adversarial Masking for Self-Supervised Learning](https://arxiv.org/abs/2201.13100)
+ [Beyond Masking: Demystifying Token-Based Pre-Training for Vision Transformers](https://arxiv.org/abs/2203.14313)
+ [Context Autoencoder for Self-Supervised Representation Learning](https://arxiv.org/abs/2202.03026)
+ [Contextual Representation Learning beyond Masked Language Modeling](https://arxiv.org/abs/2204.04163)
+ [ContrastMask: Contrastive Learning to Segment Every Thing](https://arxiv.org/abs/2203.09775)
+ [ConvMAE: Masked Convolution Meets Masked Autoencoders](https://arxiv.org/abs/2205.03892)
+ [Exploring Plain Vision Transformer Backbones for Object Detection](https://arxiv.org/abs/2203.16527)
+ [Global Contrast Masked Autoencoders Are Powerful Pathological Representation Learners](https://arxiv.org/abs/2205.09048)
+ [How to Understand Masked Autoencoders](https://arxiv.org/abs/2202.03670)
+ [IBOT: Image Bert Pre-Training With Online Tokenizer](https://arxiv.org/abs/2111.07832)
+ [MADE: Masked Autoencoder for Distribution Estimation](https://arxiv.org/abs/1502.03509)
+ [Mask Transfiner for High-Quality Instance Segmentation](https://arxiv.org/abs/2111.13673)
+ [Masked Autoencoders As Spatiotemporal Learners](https://arxiv.org/abs/2205.09113)
+ [Masked Discrimination for Self-Supervised Learning on Point Clouds](https://arxiv.org/abs/2203.11183)
+ [Masked Feature Prediction for Self-Supervised Visual Pre-Training](https://arxiv.org/abs/2112.09133)
+ [Masked Image Modeling Advances 3D Medical Image Analysis](https://arxiv.org/abs/2204.11716)
+ [Masked Siamese Networks for Label-Efficient Learning](https://arxiv.org/abs/2204.07141)
+ [MaskGIT: Masked Generative Image Transformer](https://arxiv.org/abs/2202.04200)
+ [MLIM: Vision-and-Language Model Pre-training with Masked Language and Image Modeling](https://arxiv.org/abs/2109.12178)
+ [SimMC: Simple Masked Contrastive Learning of Skeleton Representations for Unsupervised Person Re-Identification](https://arxiv.org/abs/2204.09826)
+ [VideoMAE: Masked Autoencoders are Data-Efficient Learners for Self-Supervised Video Pre-Training](https://arxiv.org/abs/2203.12602)
+ [What to Hide from Your Students: Attention-Guided Masked Image Modeling](https://arxiv.org/abs/2203.12719)
+ [Uniform Masking: Enabling MAE Pre-training for Pyramid-based Vision Transformers with Locality](https://arxiv.org/abs/2205.10063)
+ [Self-supervised 3D anatomy segmentation using self-distilled masked image transformer (SMIT)](https://arxiv.org/abs/2205.10342)
+ [FaceMAE: Privacy-Preserving Face Recognition via Masked Autoencoders](https://arxiv.org/abs/2205.11090)
+ [Deeper vs Wider: A Revisit of Transformer Configuration](https://arxiv.org/abs/2205.10505)
+ [Masked Conditional Video Diffusion for Prediction, Generation, and Interpolation](https://arxiv.org/abs/2205.09853)
+ [Green Hierarchical Vision Transformer for Masked Image Modeling](https://arxiv.org/abs/2205.13515)
+ [Revealing the Dark Secrets of Masked Image Modeling](https://arxiv.org/abs/2205.13543)
+ [MixMIM: Mixed and Masked Image Modeling for Efficient Visual Representation Learning](https://arxiv.org/abs/2205.13137)

# Graph
+ [MGAE: Masked Autoencoders for Self-Supervised Learning on Graphs](https://arxiv.org/abs/2201.02534)
+ [Graph Masked Autoencoder with Transformers](https://arxiv.org/abs/2202.08391)
+ [MaskGAE: Masked Graph Modeling Meets Graph Autoencoders](https://arxiv.org/abs/2205.10053)
+ [GraphMAE: Self-Supervised Masked Graph Autoencoders](https://arxiv.org/abs/2205.10803)

# Language
BERT is the first successful application of masked autoencoders. There has been a surge of language research focused on such masking-and-predicting paradigm, so I'm not going to report these works.

# TODO List
- [ ] Add code links
- [ ] Add conference venues
- [ ] Add more illustrative figures

