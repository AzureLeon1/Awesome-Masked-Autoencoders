# Awesome Masked Autoencoders
<img src="https://img.shields.io/badge/Contributions-Welcome-278ea5" alt="Contrib"/> <img src="https://img.shields.io/badge/Number%20of%20Papers-47-FF6F00" alt="PaperNum"/>

<p align="center"> <img width = "700" height = "380" src="mae.png" /> <p align="center">Fig. 1. Masked Autoencoders from Kaiming He et al.</p>

Masked Autoencoder (MAE, *Kaiming He et al.*) has renewed a surge of interest due to its capacity to learn useful representations from rich unlabeled data. Until recently, MAE and its follow-up works have advanced the state-of-the-art and provided valuable insights in research (particularly vision research). Here I list several follow-up works after or concurrent with MAE to inspire future research.


> *:octocat: code links.

# Vision
+ [ðŸ”¥Masked Autoencoders Are Scalable Vision Learners](https://arxiv.org/abs/2111.06377) [:octocat:](https://github.com/FlyEgle/MAE-pytorch) [:octocat:](https://github.com/pengzhiliang/MAE-pytorch)
+ [ðŸ”¥SimMIM: A Simple Framework for Masked Image Modeling](https://arxiv.org/abs/2111.09886) [:octocat:](https://github.com/microsoft/SimMIM)
+ [ðŸ”¥BEIT: BERT Pre-Training of Image Transformers](https://arxiv.org/abs/2106.08254) [:octocat:](https://github.com/microsoft/unilm/tree/master/beit)
+ [Student Collaboration Improves Self-Supervised Learning: Dual-Loss Adaptive Masked Autoencoder for Brain Cell Image Analysis](https://arxiv.org/abs/2205.05194) [:octocat:](https://github.com/hula-ai/DAMA)
+ [A Mask-Based Adversarial Defense Scheme](https://arxiv.org/abs/2204.11837)
+ [Adversarial Masking for Self-Supervised Learning](https://arxiv.org/abs/2201.13100)
+ [Beyond Masking: Demystifying Token-Based Pre-Training for Vision Transformers](https://arxiv.org/abs/2203.14313) [:octocat:](https://github.com/sunsmarterjie/beyond_masking)
+ [Context Autoencoder for Self-Supervised Representation Learning](https://arxiv.org/abs/2202.03026) [:octocat:](https://github.com/lxtGH/CAE)
+ [Contextual Representation Learning beyond Masked Language Modeling](https://arxiv.org/abs/2204.04163) [:octocat:](https://github.com/FUZHIYI/TACO)
+ [ContrastMask: Contrastive Learning to Segment Every Thing](https://arxiv.org/abs/2203.09775) [:octocat:](https://github.com/huiserwang/ContrastMask)
+ [ConvMAE: Masked Convolution Meets Masked Autoencoders](https://arxiv.org/abs/2205.03892) [:octocat:](https://github.com/Alpha-VL/ConvMAE)
+ [Exploring Plain Vision Transformer Backbones for Object Detection](https://arxiv.org/abs/2203.16527)
+ [Global Contrast Masked Autoencoders Are Powerful Pathological Representation Learners](https://arxiv.org/abs/2205.09048) [:octocat:](https://github.com/StarUniversus/gcmae)
+ [How to Understand Masked Autoencoders](https://arxiv.org/abs/2202.03670)
+ [iBOT: Image Bert Pre-Training With Online Tokenizer](https://arxiv.org/abs/2111.07832) [:octocat:](https://github.com/bytedance/ibot)
+ [MADE: Masked Autoencoder for Distribution Estimation](https://arxiv.org/abs/1502.03509) [:octocat:](https://github.com/mgermain/MADE)
+ [Mask Transfiner for High-Quality Instance Segmentation](https://arxiv.org/abs/2111.13673) [:octocat:](http://vis.xyz/pub/transfiner)
+ [Masked Autoencoders As Spatiotemporal Learners](https://arxiv.org/abs/2205.09113)
+ [Masked Discrimination for Self-Supervised Learning on Point Clouds](https://arxiv.org/abs/2203.11183) [:octocat:](https://github.com/haotian-liu/MaskPoint)
+ [Masked Feature Prediction for Self-Supervised Visual Pre-Training](https://arxiv.org/abs/2112.09133)
+ [Masked Image Modeling Advances 3D Medical Image Analysis](https://arxiv.org/abs/2204.11716) 
+ [Masked Siamese Networks for Label-Efficient Learning](https://arxiv.org/abs/2204.07141) [:octocat:](https://github.com/facebookresearch/msn)
+ [MaskGIT: Masked Generative Image Transformer](https://arxiv.org/abs/2202.04200) [:octocat:](https://github.com/google-research/maskgit)
+ [MLIM: Vision-and-Language Model Pre-training with Masked Language and Image Modeling](https://arxiv.org/abs/2109.12178)
+ [SimMC: Simple Masked Contrastive Learning of Skeleton Representations for Unsupervised Person Re-Identification](https://arxiv.org/abs/2204.09826) [:octocat:](https://github.com/Kali-Hac/SimMC)
+ [VideoMAE: Masked Autoencoders are Data-Efficient Learners for Self-Supervised Video Pre-Training](https://arxiv.org/abs/2203.12602) [:octocat:](https://github.com/MCG-NJU/VideoMAE)
+ [What to Hide from Your Students: Attention-Guided Masked Image Modeling](https://arxiv.org/abs/2203.12719)
+ [Uniform Masking: Enabling MAE Pre-training for Pyramid-based Vision Transformers with Locality](https://arxiv.org/abs/2205.10063) [:octocat:](https://github.com/implus/UM-MAE)
+ [Self-supervised 3D anatomy segmentation using self-distilled masked image transformer (SMIT)](https://arxiv.org/abs/2205.10342)
+ [FaceMAE: Privacy-Preserving Face Recognition via Masked Autoencoders](https://arxiv.org/abs/2205.11090) [:octocat:](https://github.com/kaiwang960112/FaceMAE)
+ [Deeper vs Wider: A Revisit of Transformer Configuration](https://arxiv.org/abs/2205.10505)
+ [Masked Conditional Video Diffusion for Prediction, Generation, and Interpolation](https://arxiv.org/abs/2205.09853) [:octocat:](https://github.com/voletiv/mcvd-pytorch)
+ [Green Hierarchical Vision Transformer for Masked Image Modeling](https://arxiv.org/abs/2205.13515) [:octocat:](https://github.com/LayneH/GreenMIM)
+ [Revealing the Dark Secrets of Masked Image Modeling](https://arxiv.org/abs/2205.13543)
+ [MixMIM: Mixed and Masked Image Modeling for Efficient Visual Representation Learning](https://arxiv.org/abs/2205.13137) [:octocat:](https://github.com/Sense-X/MixMIM)
+ [Contrastive Learning Rivals Masked Image Modeling in Fine-tuning via Feature Distillation](https://arxiv.org/abs/2205.14141) [:octocat:](https://github.com/SwinTransformer/Feature-Distillation)
+ [Architecture-Agnostic Masked Image Modeling -- From ViT back to CNN](https://arxiv.org/abs/2205.13943) [:octocat:](https://github.com/Westlake-AI/openmixup)
+ [SupMAE: Supervised Masked Autoencoders Are Efficient Vision Learners](https://arxiv.org/abs/2205.14540) [:octocat:](https://github.com/cmu-enyac/supmae)
+ [Object-wise Masked Autoencoders for Fast Pre-training](https://arxiv.org/abs/2205.14338)
+ [Multimodal Masked Autoencoders Learn Transferable Representations](https://arxiv.org/abs/2205.14204)
+ [MaskOCR: Text Recognition with Masked Encoder-Decoder Pretraining](https://arxiv.org/abs/2206.00311), Pengyuan Lyu, Chengquan Zhang, Shanshan Liu, Meina Qiao, Yangliu Xu, Liang Wu, Kun Yao, Junyu Han, Errui Ding, Jingdong Wang


# Audio
+ [MAE-AST: Masked Autoencoding Audio Spectrogram Transformer](https://arxiv.org/abs/2203.16691) [:octocat:](https://github.com/AlanBaade/MAE-AST-Public)


# Graph
+ [MGAE: Masked Autoencoders for Self-Supervised Learning on Graphs](https://arxiv.org/abs/2201.02534) [:octocat:](https://github.com/Qiaoyut/MGAE)
+ [Graph Masked Autoencoder with Transformers](https://arxiv.org/abs/2202.08391)
+ [MaskGAE: Masked Graph Modeling Meets Graph Autoencoders](https://arxiv.org/abs/2205.10053) [:octocat:](https://github.com/EdisonLeeeee/MaskGAE)
+ [GraphMAE: Self-Supervised Masked Graph Autoencoders](https://arxiv.org/abs/2205.10803) [:octocat:](https://github.com/THUDM/GraphMAE)

# Language (Omitted)
There has been a surge of language research focused on such masking-and-predicting paradigm, e.g. BERT, so I'm not going to report these works.

# Miscellaneous
+ [Point-M2AE: Multi-scale Masked Autoencoders for Hierarchical Point Cloud Pre-training](https://arxiv.org/abs/2205.14401) [:octocat:](https://github.com/ZrrSkywalker/Point-M2AE)
+ [Masked Bayesian Neural Networks : Computation and Optimality](https://arxiv.org/abs/2206.00853)

# TODO List
- [x] Add code links
- [ ] Add authers list
- [ ] Add conference venues
- [ ] Add more illustrative figures

